{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://github.com/elsevierlabs-os/soda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note- SoDA matches at the lucene word level. If the word itself gets changed, then SoDA will most likely not find the match."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps to start solr: 1. cd to the solr directory 2. enter the comand \"bin/solr start -p 8984\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps to start Jetty and SoDA: 1. cd to the SoDa directory 2. Enter \"sbt\" 3. Enter \"jetty:start\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sodaclient\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Establish a connection to the soda web client\n",
    "# If running local web app, will need a \"soda\" extension to the URL - http://localhost:8080/soda/\n",
    "client = sodaclient.SodaClient(\"http://localhost:8080/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soda status: {'status': 'ok', 'message': 'SoDA accepting requests (Solr version 7.3.0)'}\n",
      "Lexicons: {'status': 'ok', 'lexicons': [{'lexicon': 'companies_addr', 'count': 1000}, {'lexicon': 'companies_city', 'count': 1000}, {'lexicon': 'companies_code', 'count': 1000}, {'lexicon': 'companies_ctry', 'count': 1000}, {'lexicon': 'companies_dict', 'count': 1000}, {'lexicon': 'companies_name', 'count': 1000}]}\n"
     ]
    }
   ],
   "source": [
    "# Check the status of soda\n",
    "ind_resp = client.index()\n",
    "print(\"Soda status:\", ind_resp)\n",
    "# list the lexicons\n",
    "print(\"Lexicons:\", client.dicts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the TSV file with the complete address name that will be used to return suggestions to the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_csv('companies_dict.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Add dictionaries- alread did this, so do not need to run it in here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add_resp = client.add(lexicon_name, id, names, commit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To add lexicons command line: in sbt, enter \"run lexicon_name path_to_tsv number_of_players\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example: \"run companies_city Desktop/companies_city1.tsv 1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get user entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the company name: 1 mobile limited\n",
      "Enter the company address: 30 city road street\n",
      "Enter the city name: london\n",
      "Enter the country: uk\n",
      "Enter the postal code: ec\n"
     ]
    }
   ],
   "source": [
    "# Prompt the user to enter an address in separate fields\n",
    "name = input(\"Enter the company name: \")\n",
    "addr = input(\"Enter the company address: \")\n",
    "city = input(\"Enter the city name: \")\n",
    "ctry = input(\"Enter the country: \")\n",
    "code = input(\"Enter the postal code: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine for one longer string\n",
    "user_entry = name + \" \" + addr + \" \" + city + \" \" + ctry + \" \" + code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Searching: Step 1- Reverse Lookup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RLookup allows non-streaming matching of phrases against entries in the dictionary. In other words, it takes a shorter string that is missing info and finds matches in the dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important here to decide which matching type to use. s3sort is beneficial because it accounts for entries that are out of order. stem2 and stem3, however, are useful because they account for special characters, where s3sort does not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First- check the two most telling fields- name and address\n",
    "name = \"1 Limited Mobile\"\n",
    "addr = \"30 City\"\n",
    "city = \"\"\n",
    "ctry = \"\"\n",
    "name_rlook = (client.rlookup('companies_name', name, 's3sort'))\n",
    "addr_rlook = (client.rlookup('companies_addr', addr, 's3sort'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SoDA will give preference to the company name field. The first idea here was to check if there is only one match found in the name, then look to see if that ID was found in any of the other fields. If it was, return that address. However, because there would be hundreds of matches in the city, country, and postal code lexicons (but rlookup only return 10 matches), this was not ideal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New approach- if there is only one match in the name, calculate the edit distance between the users input and the suggested address. If the edit distance is below some threshold, return the string."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the edit distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the penalties to deviate from Levenshtein cost and remain in line with edit distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "INSERTION_PENALTY = 1\n",
    "DELETION_PENALTY = 1\n",
    "# This substitution penalty differentiates from Levenshtein cost (would be 1)\n",
    "SUBSTITUTION_PENALTY = 2\n",
    "ALLOWED_LEVELS = [\"word\", \"char\"]\n",
    "LEVEL = \"word\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function computes the minimum cost of address string by totalling the minimum edit distance (stored in the dynamic array, D) for each substring of that address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_cost(D, i, j, token_X, token_Y):\n",
    "    relative_subst_cost = 0 if token_X == token_Y else SUBSTITUTION_PENALTY\n",
    "    return min(D[i-1, j] + INSERTION_PENALTY, D[i, j-1] + DELETION_PENALTY, D[i-1, j-1] + relative_subst_cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function splits the larger address string into separate component word strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize_string(string, level=\"word\"):\n",
    "    assert level in ALLOWED_LEVELS\n",
    "    if level is \"word\":\n",
    "        return string.split(\" \")\n",
    "    else:\n",
    "        return list(string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function computes the edit distance between two strings by dynamically stroing the edit distance of each smaller substring in a 2-D array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def minimum_edit_distance(string1, string2, level=\"word\"):\n",
    "    \"\"\"The function uses the dynamic programming approach from Wagner-Fischer to compute the minimum edit distance\n",
    "    between two sequences.\n",
    "    :param string1 first sequence\n",
    "    :param string2 second sequence\n",
    "    :param level defines on which granularity the algorithm will be applied. \"word\" specifies the token to\n",
    "    be sequential words while \"char\" applies the algorithm on a character-by-character level\"\"\"\n",
    "    # Call tokenize string on the two address strings that were passed to the method\n",
    "    string1_tokens = tokenize_string(string1, level)\n",
    "    string2_tokens = tokenize_string(string2, level)\n",
    "    n = len(string1_tokens)\n",
    "    m = len(string2_tokens)\n",
    "   \n",
    "#     print(string2_tokens)\n",
    " \n",
    "    D = np.zeros((n, m))\n",
    " \n",
    "    for i in range(n):\n",
    "        for j in range(m):\n",
    "            if j == 0:\n",
    "                D[i,j] = i\n",
    "            elif i == 0:\n",
    "                D[i,j] = j\n",
    "            else:\n",
    "                D[i,j] = compute_cost(D, i, j, string1_tokens[i], string2_tokens[j])\n",
    " \n",
    "    return string2_tokens, D[n-1, m-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Case 1- There is only one match in the name dictionary. Get the address and return it if the edit distance between the suggestion and user entry is below the threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 MOBILE LIMITED 30 CITY ROAD LONDON EC1Y 2AB\n"
     ]
    }
   ],
   "source": [
    "response_soda = \"None found!\"\n",
    "if len(name_rlook['entries']) == 1:\n",
    "    name_id = name_rlook['entries'][0]['id']\n",
    "    raw_id = int(name_id.split('_')[1])\n",
    "    response_soda = (df.iloc[raw_id - 1]['NAME'])\n",
    "    dist = minimum_edit_distance(response_soda, user_entry)\n",
    "    # if the edit distance is below the threshold, return the suggestion\n",
    "    if (dist[1] > 25.0):\n",
    "        response_soda = \"None found!\"\n",
    "print(response_soda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Case 2- There are multiple matches in the name. Find corresponding IDs in the name matches and address matches. Remember another fault here- will only return max 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None found!\n"
     ]
    }
   ],
   "source": [
    "# return the one with the largest combined confidence\n",
    "response_soda = \"None found!\"\n",
    "for name in name_rlook['entries']:\n",
    "    highest_confidence = 0\n",
    "    name_id = name['id']\n",
    "    addr_id = \"ADDR_\" + name_id.split('_')[1]\n",
    "    raw_id = int(name_id.split('_')[1])\n",
    "    for addr in addr_rlook['entries']:\n",
    "        if addr['id'] == addr_id:\n",
    "            conf = (name['confidence'] + addr['confidence'])\n",
    "            confidence = max(highest_confidence, conf)\n",
    "            if conf > highest_confidence:\n",
    "                response_soda = (df.iloc[raw_id - 1]['NAME'])\n",
    "print(response_soda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Case 3- If there is only one match in the addresses lexicon, return that full address. It would not be useful to check corresponding IDs in city, country, and code in the case that there are multiple address matches due to the 10 match maximum. If none of these 3 cases work, more on to step 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None found!\n"
     ]
    }
   ],
   "source": [
    "response_soda = \"None found!\"\n",
    "if len(addr_rlook['entries']) == 1:\n",
    "    addr_id = addr_rlook['entries'][0]['id']\n",
    "    raw_id = int(addr_id.split('_')[1])\n",
    "    response_soda = (df.iloc[raw_id - 1]['NAME'])\n",
    "    dist = minimum_edit_distance(response_soda, user_entry)\n",
    "    # if the edit distance is below the threshold, return the suggestion\n",
    "    if (dist[1] > 25.0):\n",
    "        response_soda = \"None found!\"\n",
    "print(response_soda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Searching: Step 2- Annotate\n",
    "There are faults with rlookup, so we use the annotate method as a backup. For example, rlookup will only return a maximum of 10 matches, so vague searches or searches in the city, country, and postal code dictionaries will not be useful. If no results are found in rlookup, then we will use annotate, which is useful if the user enters information in the wrong field, or adds additional and unnecessary information to the address."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This implementation will find addresses such as 1 Mobile Limited Company London UK, that rlookup would not find."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take the input as one large string and annotate it against each separate lexicon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_entry = \"1 Mobile Limited Company in the city of london\"\n",
    "name_annot = client.annot('companies_name', user_entry, 'stem2')\n",
    "addr_annot = client.annot('companies_addr', user_entry, 'stem2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Case 1- There is only one match in the name dictionary. If that matching ID exists in some other lexicon match, then return the full address."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 MOBILE LIMITED 30 CITY ROAD LONDON EC1Y 2AB\n"
     ]
    }
   ],
   "source": [
    "# case 1- there is only one match in the name dictionary\n",
    "response_soda = \"None found!\"\n",
    "if len(name_annot['annotations']) == 1:\n",
    "    raw_id = int(name_id.split('_')[1])\n",
    "    name_id = name_annot['annotations'][0]['id']\n",
    "    addr_id = \"ADDR_\" + name_id.split('_')[1]\n",
    "    dict_id = \"DICT_\" + name_id.split('_')[1]\n",
    "    #First, check if there is a matching address with the same ID\n",
    "    found = False\n",
    "    for entry in addr_annot['annotations']:\n",
    "        if entry['id'] == addr_id:\n",
    "            found = True\n",
    "            # print the full name and address to recommend to user\n",
    "            response_soda = (df.iloc[raw_id - 1]['NAME'])\n",
    "    # Next, check city\n",
    "    if found == False:\n",
    "        city_id = \"CITY_\" + name_id.split('_')[1]\n",
    "        city_annot = (client.annot('companies_city', user_entry, 'stem2'))\n",
    "        for entry in city_annot['annotations']:\n",
    "            if entry['id'] == city_id:\n",
    "                found = True\n",
    "                # print the full name and address to recommend to user\n",
    "                response_soda = (df.iloc[raw_id - 1]['NAME'])\n",
    "    # Then check country\n",
    "    if found == False:\n",
    "        ctry_id = \"CTRY_\" + name_id.split('_')[1]\n",
    "        ctry_annot = (client.annot('companies_ctry', user_entry, 'stem2'))\n",
    "        for entry in ctry_annot['annotations']:\n",
    "            if entry['id'] == ctry_id:\n",
    "                found = True\n",
    "                # print the full name and address to recommend to user\n",
    "                response_soda = (df.iloc[raw_id - 1]['NAME'])\n",
    "    # Finally, check postal code\n",
    "    if found == False:\n",
    "        code_id = \"CODE_\" + name_id.split('_')[1]\n",
    "        code_annot = (client.annot('companies_code', user_entry, 'stem2'))\n",
    "        for entry in code_annot['annotations']:\n",
    "            if entry['id'] == code_id:\n",
    "                found = True\n",
    "                # print the full name and address to recommend to user\n",
    "                response_soda = (df.iloc[raw_id - 1]['NAME'])\n",
    "                \n",
    "print(response_soda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Case 2- There are multiple name matches found. Find corresponding IDs in the addr matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 MOBILE LIMITED 30 CITY ROAD LONDON EC1Y 2AB\n"
     ]
    }
   ],
   "source": [
    "# return the one with the largest combined confidence\n",
    "response_soda = \"None found!\"\n",
    "for name in name_annot['annotations']:\n",
    "    highest_confidence = 0\n",
    "    name_id = name['id']\n",
    "    addr_id = \"ADDR_\" + name_id.split('_')[1]\n",
    "    raw_id = int(name_id.split('_')[1])\n",
    "    for addr in addr_annot['annotations']:\n",
    "        if addr['id'] == addr_id:\n",
    "            conf = (name['confidence'] + addr['confidence'])\n",
    "            confidence = max(highest_confidence, conf)\n",
    "            if conf > highest_confidence:\n",
    "                response_soda = (df.iloc[raw_id - 1]['NAME'])\n",
    "print(response_soda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Case 3- There is only one match in the address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None found!\n"
     ]
    }
   ],
   "source": [
    "response_soda = \"None found!\"\n",
    "if len(addr_annot['annotations']) == 1:\n",
    "    addr_id = addr_annot['annotations'][0]['id']\n",
    "    raw_id = int(addr_id.split('_')[1])\n",
    "    response_soda = (df.iloc[raw_id - 1]['NAME'])\n",
    "    dist = minimum_edit_distance(response_soda, user_entry)\n",
    "    # if the edit distance is below the threshold, return the suggestion\n",
    "    if (dist[1] > 25.0):\n",
    "        response_soda = \"None found!\"\n",
    "print(response_soda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3- Combination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last case to account for is when too much info is added to one field, but too little is added in another? Such as 1 Mobile Limited Company 30 City. Here, we must use a combination of Reverse Lookup and Annotate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by checking if there is a match for name through the annotation method. Run those IDs against the matches found with the addresses reverse lookup method. Return the match with the highest confidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 MOBILE LIMITED 30 CITY ROAD LONDON EC1Y 2AB\n"
     ]
    }
   ],
   "source": [
    "response_soda = \"None found!\"\n",
    "for name in name_annot['annotations']:\n",
    "    highest_confidence = 0\n",
    "    name_id = name['id']\n",
    "    addr_id = \"ADDR_\" + name_id.split('_')[1]\n",
    "    raw_id = int(name_id.split('_')[1])\n",
    "    for addr in addr_rlook['annotations']:\n",
    "        if addr['id'] == addr_id:\n",
    "            conf = (name['confidence'] + addr['confidence'])\n",
    "            confidence = max(highest_confidence, conf)\n",
    "            if conf > highest_confidence:\n",
    "                response_soda = (df.iloc[raw_id - 1]['NAME'])\n",
    "print(response_soda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Work and Notes\n",
    "Examples of stem vs. s3sort are below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'status': 'ok', 'entries': [{'id': 'NAME_645', 'lexicon': 'companies_name', 'text': 'THE BULL STUDIO LTD', 'confidence': 0.5263157894736842}]}\n"
     ]
    }
   ],
   "source": [
    "name2 = \"Bull stúdios\" #ORIGINAL IS \"THE BULL STUDIO LTD\"\n",
    "print(client.rlookup('companies_name', name2, 'stem3'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'status': 'ok', 'entries': [{'id': 'NAME_645', 'lexicon': 'companies_name', 'text': 'THE BULL STUDIO LTD', 'confidence': 0.7368421052631579}]}\n"
     ]
    }
   ],
   "source": [
    "name2 = \"Bull studio ltd.\" #ORIGINAL IS \"THE BULL STUDIO LTD\"\n",
    "print(client.rlookup('companies_name', name2, 's3sort'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case lexicons need to be deleted and reloaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# resp = client.delete('companies_name', \"*\")\n",
    "# resp1 = client.delete('companies_addr', \"*\")\n",
    "# resp2 = client.delete('companies_city1', \"*\")\n",
    "# resp3 = client.delete('companies_zip', \"*\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
