{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entity Resolution- Dedupe Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import Statements\n",
    "from __future__ import print_function\n",
    "from future.builtins import next\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import re\n",
    "import collections\n",
    "import numpy\n",
    "\n",
    "import dedupe\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the output_file will store the results of the record linkage deduplication\n",
    "output_file = 'data_matching_output.csv'\n",
    "\n",
    "# the settings file will contain the data model and predicates that determine matches\n",
    "settings_file = 'data_matching_learned_settings'\n",
    "\n",
    "# the training_file will contain the pairs of labeled examples that the model was trained on\n",
    "training_file = 'data_matching_training.json'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# method to clean the data using Unidecode and Regex\n",
    "\n",
    "def preProcess(column):\n",
    "    # convert any unicode data into ASCII characters\n",
    "    column = unidecode(column)\n",
    "    # ignore new lines\n",
    "    column = re.sub('\\n', ' ', column)\n",
    "    # ignore special characters\n",
    "    column = re.sub('-', '', column)\n",
    "    column = re.sub('/', ' ', column)\n",
    "    column = re.sub(\"'\", '', column)\n",
    "    column = re.sub(\",\", '', column)\n",
    "    column = re.sub(\":\", ' ', column)\n",
    "    # ignore extra white space\n",
    "    column = re.sub('  +', ' ', column)\n",
    "    # ignore casing\n",
    "    column = column.strip().strip('\"').strip(\"'\").lower().strip()\n",
    "    if not column :\n",
    "        column = None\n",
    "    return column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read the data from the CSV and create a dictionary of addresses\n",
    "\n",
    "def readData(filename):\n",
    "    \n",
    "    # initialize the dictionary\n",
    "    data_d = {}\n",
    "\n",
    "    # read each row in the CSV, clean the data, and it to a dictionary\n",
    "    with open(filename) as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for i, row in enumerate(reader):\n",
    "            clean_row = dict([(k, preProcess(v)) for (k, v) in row.items()])\n",
    "            # each address will have a unique ID consisting of the file name and a unique number\n",
    "            data_d[filename + str(i)] = dict(clean_row)\n",
    "\n",
    "    return data_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the data\n",
    "data_1 = readData('new_companies.csv')\n",
    "data_2 = readData('new_companies_users.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:dedupe.api:((SimplePredicate: (sortedAcronym, Full_Address), TfidfNGramSearchPredicate: (0.6, CompanyName)), (SimplePredicate: (commonThreeTokens, CompanyName), TfidfTextSearchPredicate: (0.4, Full_Address)), (SimplePredicate: (firstIntegerPredicate, CompanyName), TfidfNGramSearchPredicate: (0.6, Full_Address)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading from data_matching_learned_settings\n"
     ]
    }
   ],
   "source": [
    "# if there already exists a settings_file (with the data model),\n",
    "# create a Dedupe object (linker) that will load the saved settings\n",
    "if os.path.exists(settings_file):\n",
    "    print('reading from', settings_file)\n",
    "    with open(settings_file, 'rb') as sf :\n",
    "        # create a record link object for saved settings- pass the data model to it\n",
    "        linker = dedupe.StaticRecordLink(sf)\n",
    "\n",
    "# if there is no previously saved settings data, create it\n",
    "else:\n",
    "    # Define the fields the linker will pay attention to\n",
    "    # Specifying fields refines the comparison methods so not each part of the record are compared equally\n",
    "    # for example, dedupe will learn which of these fields have higher weights (more important in determining matches) by using regularized logistic regression\n",
    "    # String types compared using affine gap string distance\n",
    "    # Note- the address field is only for US addresses (uses usaddress package to split into components)\n",
    "        # must have dedupe-variable-address installed to use this\n",
    "    fields = [\n",
    "        {'field' : 'CompanyName', 'type': 'String'},\n",
    "        {'field' : 'Full_Address', 'type': 'String'},]\n",
    "    \n",
    "    # Create a new linker object\n",
    "    linker = dedupe.RecordLink(fields)\n",
    "    # To train the linker, feed it a sample of records.\n",
    "    linker.sample(data_1, data_2, 15000)\n",
    "\n",
    "    \n",
    "    # If we have training data saved from a previous run of linker,\n",
    "    # look for it and load it in.\n",
    "    if os.path.exists(training_file):\n",
    "        print('reading labeled examples from ', training_file)\n",
    "        with open(training_file) as tf :\n",
    "            linker.readTraining(tf)\n",
    "\n",
    "    # ## Active learning\n",
    "    # Dedupe will find the next pair of records\n",
    "    # it is least certain about and ask for them to be labelled as matches\n",
    "    # or not.\n",
    "    print('starting active labeling...')\n",
    "\n",
    "    # Label examples, add them to the training data, and update the mathcing model\n",
    "    dedupe.consoleLabel(linker)\n",
    "\n",
    "    linker.train()\n",
    "\n",
    "    # When finished, save training data as labeled examples in the training_file\n",
    "    with open(training_file, 'w') as tf :\n",
    "        linker.writeTraining(tf)\n",
    "\n",
    "    # Save weights and predicates.  If the settings file\n",
    "    # exists, skip all the training and learning next time we run\n",
    "    # this file.\n",
    "    with open(settings_file, 'wb') as sf :\n",
    "        linker.writeSettings(sf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Blocking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "# Split the data up into groups of records with some feature in common\n",
    "# Only comparing the entries in these blocks reduces number of comparisons\n",
    "# This is more useful with larger datasets- where we would use a representative sample rather than all the data\n",
    "# 2 blocking methods- predicate blocks and index (using inverted index)\n",
    "blocks = linker._blockData(data_1,data_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate precision, recall, threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:dedupe.api:0 records\n",
      "INFO:dedupe.api:100 records\n",
      "INFO:dedupe.api:200 records\n",
      "INFO:dedupe.api:300 records\n",
      "INFO:dedupe.api:400 records\n",
      "INFO:dedupe.api:500 records\n",
      "INFO:dedupe.api:600 records\n"
     ]
    }
   ],
   "source": [
    "# the records will be duplicates\n",
    "candidate_records = itertools.chain.from_iterable(linker._blockedPairs(blocks))\n",
    "\n",
    "# Calculate the probability that pair of records are duplicates\n",
    "probability = dedupe.core.scoreDuplicates(candidate_records,\n",
    "                                           linker.data_model,\n",
    "                                           linker.classifier,\n",
    "                                           linker.num_cores)['score']\n",
    "\n",
    "probability = probability.copy()\n",
    "probability.sort()\n",
    "probability = probability[::-1]\n",
    "\n",
    "expected_dupes = numpy.cumsum(probability)\n",
    "\n",
    "# Recall- TP/(TP + FN) - ability to find all interesting data points\n",
    "recall = expected_dupes / expected_dupes[-1]\n",
    "# Precision- TP/(TP + FP) - take the probability that the pairs are duplicates divided by the total number of duplicates\n",
    "precision = expected_dupes / numpy.arange(1, len(expected_dupes) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probability: [0.96879673 0.96879673 0.96879673 0.96202236 0.9612511  0.94986814\n",
      " 0.9401054  0.93533444 0.92907256 0.9132344  0.9129198  0.9129198\n",
      " 0.90678036 0.88700145 0.8788225  0.8554713  0.8476454  0.83515435\n",
      " 0.8046382  0.7958472  0.77570057 0.7610263  0.69086343 0.68097645\n",
      " 0.6603313  0.54154974 0.44843125 0.44843125 0.36229447 0.301954\n",
      " 0.21531999 0.14224826 0.13657743 0.11743887 0.08842647 0.07917296\n",
      " 0.06073797 0.03264759]\n",
      "expected duplicates: [ 0.96879673  1.9375935   2.9063902   3.8684125   4.8296638   5.779532\n",
      "  6.7196374   7.654972    8.584044    9.497279   10.410199   11.323119\n",
      " 12.229899   13.1169     13.995723   14.851194   15.69884    16.533995\n",
      " 17.338633   18.13448    18.91018    19.671206   20.362068   21.043045\n",
      " 21.703377   22.244926   22.693357   23.141788   23.504084   23.806038\n",
      " 24.021358   24.163607   24.300184   24.417624   24.50605    24.585222\n",
      " 24.64596    24.678608  ]\n",
      "recall: [0.03925654 0.07851308 0.11776961 0.15675165 0.19570243 0.23419197\n",
      " 0.2722859  0.31018654 0.34783342 0.38483852 0.4218309  0.45882326\n",
      " 0.49556682 0.5315089  0.5671196  0.6017841  0.6361315  0.6699727\n",
      " 0.7025774  0.73482585 0.76625794 0.7970954  0.8250898  0.8526836\n",
      " 0.8794409  0.90138495 0.91955584 0.9377267  0.9524072  0.96464264\n",
      " 0.97336763 0.9791317  0.98466593 0.98942465 0.9930078  0.99621594\n",
      " 0.9986771  1.        ]\n",
      "precision: [0.96879673 0.96879673 0.96879673 0.96710312 0.96593275 0.96325533\n",
      " 0.9599482  0.95687151 0.95378272 0.94972792 0.94638174 0.94359326\n",
      " 0.94076149 0.93692146 0.93304818 0.92819965 0.92346118 0.91855526\n",
      " 0.91255961 0.90672398 0.90048472 0.89414571 0.88530731 0.87679354\n",
      " 0.86813507 0.85557409 0.84049472 0.82649245 0.81048564 0.7935346\n",
      " 0.77488253 0.75511271 0.73636922 0.7181654  0.70017286 0.68292284\n",
      " 0.66610702 0.64943705]\n"
     ]
    }
   ],
   "source": [
    "print(\"probability:\", probability)\n",
    "print(\"expected duplicates:\", expected_dupes)\n",
    "print(\"recall:\",recall)\n",
    "print(\"precision:\",precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWhkUkqRW/x9wNjQ4NyVBxwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10b7da630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the predicted precision-recall plot\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.step(recall, precision, color='b', alpha=.2, where='post')\n",
    "plt.fill_between(recall, precision, step='post', alpha=0.2,\n",
    "                 color='b')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('Precision-Recall curve')\n",
    "plt.show()\n",
    "\n",
    "# PR curve looks nearly perfect due to small amounts of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:dedupe.api:0 records\n",
      "INFO:dedupe.api:100 records\n",
      "INFO:dedupe.api:200 records\n",
      "INFO:dedupe.api:300 records\n",
      "INFO:dedupe.api:400 records\n",
      "INFO:dedupe.api:500 records\n",
      "INFO:dedupe.api:600 records\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum expected recall and precision\n",
      "recall: %2.3f 0.90138495\n",
      "precision: %2.3f 0.8555740943321815\n",
      "With threshold: %2.3f 0.54154974\n",
      "Threshold to maximize expected F score = 0.54154974\n",
      "clustering...\n"
     ]
    }
   ],
   "source": [
    "# Find the threshold that will maximize a weighted average of our\n",
    "# precision and recall (F Score) for a sample of data.  When we set the recall weight to 2, we are\n",
    "# saying we care twice as much about recall as we do precision.\n",
    "#\n",
    "# The weighted avg, or F-score = 2tp/(2tp + fp + fn)\n",
    "# \n",
    "# In this case, set the recall_weight to .5- saying we care twice as much about precision\n",
    "# as we do recall. When matching the data, set the threshold closer to 1 to raise precision\n",
    "# \n",
    "# This is called hierarchical clustering with centroid linkage\n",
    "# Example- A is related to B, C is related to B, so those would all be clustered with B as centroid\n",
    "# The threshold determines the minimum probability for a record to be related to the centroid\n",
    "\n",
    "recall_weight = .9\n",
    "\n",
    "score = recall * precision / (recall + recall_weight ** 2 * precision)\n",
    "\n",
    "i = numpy.argmax(score)\n",
    "\n",
    "print('Maximum expected recall and precision')\n",
    "print('recall: %2.3f', recall[i])\n",
    "print('precision: %2.3f', precision[i])\n",
    "print('With threshold: %2.3f', probability[i])\n",
    "\n",
    "calcThreshold= probability[i]\n",
    "\n",
    "print(\"Threshold to maximize expected F score =\", calcThreshold )\n",
    "\n",
    "\n",
    "print('clustering...')\n",
    "linked_records = linker.match(data_1, data_2, threshold=calcThreshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# duplicate sets 9\n"
     ]
    }
   ],
   "source": [
    "print('# duplicate sets', len(linked_records))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write our original data back out to a CSV with a new column called \n",
    "# 'Cluster ID' which indicates which records refer to each other.\n",
    "\n",
    "cluster_membership = {}\n",
    "cluster_id = None\n",
    "for cluster_id, (cluster, score) in enumerate(linked_records):\n",
    "    for record_id in cluster:\n",
    "        cluster_membership[record_id] = (cluster_id, score)\n",
    "\n",
    "if cluster_id :\n",
    "    unique_id = cluster_id + 1\n",
    "else :\n",
    "    unique_id =0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(output_file, 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    \n",
    "    header_unwritten = True\n",
    "\n",
    "    for fileno, filename in enumerate(('company_addresses.csv', 'company_addresses_users.csv')) :\n",
    "        with open(filename) as f_input :\n",
    "            reader = csv.reader(f_input)\n",
    "\n",
    "            if header_unwritten :\n",
    "                heading_row = next(reader)\n",
    "                heading_row.insert(0, 'source file')\n",
    "                heading_row.insert(0, 'Link Score')\n",
    "                heading_row.insert(0, 'Cluster ID')\n",
    "                writer.writerow(heading_row)\n",
    "                header_unwritten = False\n",
    "            else :\n",
    "                next(reader)\n",
    "\n",
    "            for row_id, row in enumerate(reader):\n",
    "                cluster_details = cluster_membership.get(filename + str(row_id))\n",
    "                if cluster_details is None :\n",
    "                    cluster_id = unique_id\n",
    "                    unique_id += 1\n",
    "                    score = None\n",
    "                else :\n",
    "                    cluster_id, score = cluster_details\n",
    "                row.insert(0, fileno)\n",
    "                row.insert(0, score)\n",
    "                row.insert(0, cluster_id)\n",
    "                writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the company name: \n",
      "Enter the address: \n"
     ]
    }
   ],
   "source": [
    "name = input('Enter the company name: ')\n",
    "addr = input('Enter the address: ')\n",
    "# state = input('Enter the state: ')\n",
    "# zip_code = input('Enter the zip code: ')\n",
    "\n",
    "# create a new file that will contain the user's entry\n",
    "user_input_file = 'user_input_file.csv'\n",
    "with open (user_input_file, 'w', newline='') as csvfile:\n",
    "    fieldnames = ['id', 'CompanyName', 'Full_Address']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerow({'id' : \"1\", 'CompanyName':name, 'Full_Address': addr})\n",
    "csvfile.close()\n",
    "\n",
    "#AB TECHSYS LTD \t INTERNATIONAL HOUSE 24 HOLBORN VIADUCT LONDON EC1A 2BN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_entry = readData('user_input_file.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# now, need to update the settings file and training file when user enters a new address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:dedupe.api:0 records\n",
      "INFO:dedupe.api:100 records\n",
      "INFO:dedupe.api:200 records\n",
      "INFO:dedupe.api:300 records\n",
      "INFO:dedupe.api:400 records\n",
      "INFO:dedupe.api:500 records\n",
      "INFO:dedupe.api:600 records\n"
     ]
    },
    {
     "ename": "BlockingError",
     "evalue": "No records have been blocked together. Is the data you are trying to match like the data you trained on?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBlockingError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-2f68ebf83ea7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_entry\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/dedupe/api.py\u001b[0m in \u001b[0;36mmatch\u001b[0;34m(self, data_1, data_2, threshold, generator)\u001b[0m\n\u001b[1;32m    373\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mclusters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclusters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pragma: no cover\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/dedupe/api.py\u001b[0m in \u001b[0;36mmatchBlocks\u001b[0;34m(self, blocks, threshold, *args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m                                        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m                                        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_cores\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m                                        threshold=0)\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"matching done, begin clustering\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/dedupe/core.py\u001b[0m in \u001b[0;36mscoreDuplicates\u001b[0;34m(records, data_model, classifier, num_cores, threshold)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0mfirst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpeek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfirst\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m         raise BlockingError(\"No records have been blocked together. \"\n\u001b[0m\u001b[1;32m    216\u001b[0m                             \u001b[0;34m\"Is the data you are trying to match like \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m                             \"the data you trained on?\")\n",
      "\u001b[0;31mBlockingError\u001b[0m: No records have been blocked together. Is the data you are trying to match like the data you trained on?"
     ]
    }
   ],
   "source": [
    "match = linker.match(data_1, data_entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# pickle.dump(readData, open(\"read_data_obj\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# x = pickle.load(open(\"read_data_obj\",'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# x(\"company_addresses.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# x = linker.match(data_1, data_entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'match' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-8e8d04d1c3a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'match' is not defined"
     ]
    }
   ],
   "source": [
    "id = int(data_1[match[0][0][0]]['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not builtin_function_or_method",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-ca781b6e80cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrows\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not builtin_function_or_method"
     ]
    }
   ],
   "source": [
    "with open('new_companies.csv', 'r') as my_file:\n",
    "    reader = csv.reader(my_file)\n",
    "    rows = list(reader)\n",
    "    print (rows[id][1] + \" \" + rows[id][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
