{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import csv\n",
    "from unidecode import unidecode\n",
    "import recordlinkage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Make Record Pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Block Indexing for Record Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#############   BLOCK INDEXING\n",
    "def runBlock():  \n",
    "    block = 0\n",
    "    both = 0\n",
    "    \n",
    "    #Next, check for exact match in name\n",
    "    blockName = recordlinkage.BlockIndex(on=['name'])\n",
    "    blockNamePairs = blockName.index(dfA, dfB)\n",
    "    if len(blockNamePairs) > 0:\n",
    "         block += 1\n",
    "    \n",
    "    #Next, check for exact match in addr    \n",
    "    blockAddr = recordlinkage.BlockIndex(on=['addr'])\n",
    "    blockAddrPairs = blockAddr.index(dfA, dfB)\n",
    "    if len(blockAddrPairs) > 0:\n",
    "        block += 2\n",
    "        \n",
    "    #Next, check for exact match in name AND addr    \n",
    "    blockNA = recordlinkage.BlockIndex(on=['name','addr'])\n",
    "    blockNAPairs = blockNA.index(dfA, dfB)\n",
    "    if len(blockNAPairs) > 0:\n",
    "        both = 1 \n",
    "    \n",
    "    if both == 1:\n",
    "    #grab the id and contents of addr match\n",
    "        return(returnResultsMI(blockNAPairs))\n",
    "    else:\n",
    "        \n",
    "        if block == 0:\n",
    "        #run sorted neighborhood both\n",
    "            runSort()\n",
    "        if block == 1:\n",
    "        #grab the id and contents of name match\n",
    "            if len(blockNamePairs) > 1:\n",
    "                runCompName(blockNamePairs)\n",
    "            else:\n",
    "                return(returnResultsMI(blockNamePairs))        \n",
    "        if block == 2:\n",
    "            #grab the id and contents of addr match\n",
    "            if len(blockAddrPairs) > 1:\n",
    "                runCompAddr(blockAddrPairs)\n",
    "            else:\n",
    "                return(returnResultsMI(blockAddrPairs))\n",
    "        if block == 3:\n",
    "            #matches both, inconclusive\n",
    "            runSort()\n",
    "        \n",
    "\n",
    "###############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Sorted Neighborhood Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#############   SORTED NEIGHBORHOOD INDEXING\n",
    "def runSort():\n",
    "    sort = 0\n",
    "\n",
    "    sortedNameIndexer = recordlinkage.SortedNeighbourhoodIndex(on='name')\n",
    "    sortedNamePairs = sortedNameIndexer.index(dfA, dfB)\n",
    "    if len(sortedNamePairs) > 0:\n",
    "        sort += 1\n",
    "\n",
    "    sortedAddrIndexer = recordlinkage.SortedNeighbourhoodIndex(on='addr')\n",
    "    sortedAddrPairs = sortedAddrIndexer.index(dfA, dfB)\n",
    "    if len(sortedAddrPairs) > 0:\n",
    "        sort += 2\n",
    "\n",
    "    if sort == 0:\n",
    "        #run sorted neighborhood both\n",
    "        runFull()\n",
    "    if sort == 1:\n",
    "        #compare with name pairs\n",
    "        runCompName(sortedNamePairs)\n",
    "    if sort == 2:\n",
    "        #compare with addr pairs\n",
    "        runCompAddr(sortedAddrPairs)\n",
    "    if sort == 3:\n",
    "        #compare with both pairs?\n",
    "        runCompBoth(sortedNamePairs, sortedAddrPairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Compare Record Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def runCompBoth(name_pairs,addr_pairs):\n",
    "    compare = recordlinkage.Compare()\n",
    "\n",
    "    compare.string('name', 'name', method='jarowinkler', threshold=0.95)\n",
    "    compare.string('addr', 'addr', method='jarowinkler', threshold=0.95)\n",
    "    compare.exact('city', 'city')\n",
    "    compare.exact('ctry', 'ctry')\n",
    "    compare.string('code', 'code', method='jarowinkler', threshold=0.90)\n",
    "    \n",
    "    nameMatch = False\n",
    "    addrMatch = False\n",
    "    # The comparison vectors for name\n",
    "    featuresName = compare.compute(name_pairs, dfA, dfB)\n",
    "    \n",
    "    # The comparison vectors for addr\n",
    "    featuresAddr = compare.compute(addr_pairs, dfA, dfB)\n",
    "\n",
    "    ########## Classification\n",
    "\n",
    "    featuresName.sum(axis=1).value_counts().sort_index(ascending=False)\n",
    "    \n",
    "    matchesNameAll = featuresName[featuresName.sum(axis=1) > 4]\n",
    "    if len(matchesNameAll) > 0:\n",
    "        nameMatch = True \n",
    "        matchesName = matchesNameAll #overwriting the larger set of results\n",
    "    else:\n",
    "        matchesName = featuresName[featuresName.sum(axis=1) > 3]\n",
    "        if len(matchesName) > 0:\n",
    "            nameMatch = True\n",
    "\n",
    "\n",
    "    featuresAddr.sum(axis=1).value_counts().sort_index(ascending=False)\n",
    "    \n",
    "    matchesAddrAll = featuresAddr[featuresAddr.sum(axis=1) > 4]\n",
    "    if len(matchesAddrAll) > 0:\n",
    "        addrMatch = True \n",
    "        matchesAddr = matchesAddrAll #overwriting the larger set of results\n",
    "    else:\n",
    "        matchesAddr = featuresAddr[featuresAddr.sum(axis=1) > 3]\n",
    "        if len(matchesAddr) > 0:\n",
    "            addrMatch = True\n",
    "    \n",
    "########## FSM\n",
    "\n",
    "    if (not nameMatch):\n",
    "        if (not addrMatch):\n",
    "            #run sorted neighborhood both\n",
    "            runFull()\n",
    "        elif (addrMatch):\n",
    "            #grab the id and contents of addr match, 11 = preference towards addr\n",
    "            if len(matchesAddr) > 2:\n",
    "                runFull()\n",
    "            else:\n",
    "                return(returnResultsDF(matchesAddr))\n",
    "    if (nameMatch):\n",
    "        if(not addrMatch):\n",
    "            #grab the id and contents of name match\n",
    "            if len(matchesName) > 2:\n",
    "                runFull()\n",
    "            else:            \n",
    "                return(returnResultsDF(matchesName))\n",
    "        elif(addrMatch): \n",
    "            if len(matchesName) == 1:\n",
    "                return(returnResultsDF(matchesName))\n",
    "            elif len(matchesAddr) == 1:\n",
    "                return(returnResultsDF(matchesAddr))\n",
    "            else:\n",
    "                runFull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######### Specify to neighborhood & Compare\n",
    "def runCompName(name_pairs):\n",
    "    \n",
    "    compare = recordlinkage.Compare()\n",
    "\n",
    "    compare.string('name', 'name', method='jarowinkler', threshold=0.95)\n",
    "    compare.string('addr', 'addr', method='jarowinkler', threshold=0.95)\n",
    "    compare.exact('city', 'city')\n",
    "    compare.exact('ctry', 'ctry')\n",
    "    compare.string('code', 'code', method='jarowinkler', threshold=0.90)\n",
    "    \n",
    "    nameMatch = False\n",
    "    addrMatch = False\n",
    "    # The comparison vectors for name\n",
    "    featuresName = compare.compute(name_pairs, dfA, dfB)\n",
    "\n",
    "    ########## Classification\n",
    "\n",
    "    featuresName.sum(axis=1).value_counts().sort_index(ascending=False)\n",
    "    \n",
    "    matchesNameAll = featuresName[featuresName.sum(axis=1) > 4]\n",
    "    if len(matchesNameAll) > 0:\n",
    "        nameMatch = True \n",
    "        matchesName = matchesNameAll #overwriting the larger set of results\n",
    "    else:\n",
    "        matchesName = featuresName[featuresName.sum(axis=1) > 3]\n",
    "        if len(matchesName) > 0:\n",
    "            nameMatch = True\n",
    "\n",
    "########## FSM\n",
    "\n",
    "    if (not nameMatch):\n",
    "        if (not addrMatch):\n",
    "            #run sorted neighborhood both\n",
    "            runFull()\n",
    "        elif (addrMatch):\n",
    "            #grab the id and contents of addr match, 11 = preference towards addr\n",
    "            if len(matchesAddr) > 2:\n",
    "                runFull()\n",
    "            else:\n",
    "                return(returnResultsDF(matchesAddr))\n",
    "    if (nameMatch):\n",
    "        if(not addrMatch):\n",
    "            #grab the id and contents of name match\n",
    "            if len(matchesName) > 2:\n",
    "                runFull()\n",
    "            else:            \n",
    "                return(returnResultsDF(matchesName))\n",
    "        elif(addrMatch): \n",
    "            #grab the id and contents of addr match, 11 = preference towards addr\n",
    "            runFull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######### Specify to neighborhood & Compare\n",
    "def runCompAddr(addr_pairs):\n",
    "    \n",
    "    compare = recordlinkage.Compare()\n",
    "\n",
    "    compare.string('name', 'name', method='jarowinkler', threshold=0.95)\n",
    "    compare.string('addr', 'addr', method='jarowinkler', threshold=0.95)\n",
    "    compare.exact('city', 'city')\n",
    "    compare.exact('ctry', 'ctry')\n",
    "    compare.string('code', 'code', method='jarowinkler', threshold=0.90)\n",
    "    \n",
    "    nameMatch = False\n",
    "    addrMatch = False\n",
    "    # The comparison vectors for addr\n",
    "    featuresAddr = compare.compute(addr_pairs, dfA, dfB)\n",
    "\n",
    "    ########## Classification\n",
    "\n",
    "    featuresAddr.sum(axis=1).value_counts().sort_index(ascending=False)\n",
    "    \n",
    "    matchesAddrAll = featuresAddr[featuresAddr.sum(axis=1) > 4]\n",
    "    if len(matchesAddrAll) > 0:\n",
    "        addrMatch = True \n",
    "        matchesAddr = matchesAddrAll #overwriting the larger set of results\n",
    "    else:\n",
    "        matchesAddr = featuresAddr[featuresAddr.sum(axis=1) > 3]\n",
    "        if len(matchesAddr) > 0:\n",
    "            addrMatch = True\n",
    "    \n",
    "########## FSM\n",
    "    if (not nameMatch):\n",
    "        if (not addrMatch):\n",
    "            #run sorted neighborhood both\n",
    "            runFull()\n",
    "        elif (addrMatch):\n",
    "            #grab the id and contents of addr match, 11 = preference towards addr\n",
    "            if len(matchesAddr) > 2:\n",
    "                runFull()\n",
    "            else:\n",
    "                return(returnResultsDF(matchesAddr))\n",
    "    if (nameMatch):\n",
    "        if(not addrMatch):\n",
    "            #grab the id and contents of name match\n",
    "            if len(matchesName) > 2:\n",
    "                runFull()\n",
    "            else:            \n",
    "                return(returnResultsDF(matchesName))\n",
    "        elif(addrMatch): \n",
    "            #grab the id and contents of addr match, 11 = preference towards addr\n",
    "            runFull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Classification and Matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Full Index Pairs and Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####### If nothing else finds matches, run FULL INDEX\n",
    "def runFull():\n",
    "    compare = recordlinkage.Compare()\n",
    "\n",
    "    compare.string('name', 'name', method='jarowinkler', threshold=0.90)\n",
    "    compare.string('addr', 'addr', method='jarowinkler', threshold=0.95)\n",
    "    compare.exact('city', 'city')\n",
    "    compare.exact('ctry', 'ctry')\n",
    "    compare.string('code', 'code', method='jarowinkler', threshold=0.90)\n",
    "    \n",
    "    fullIndexer = recordlinkage.FullIndex()\n",
    "    fullIndexPairs = fullIndexer.index(dfA, dfB)\n",
    "\n",
    "    featuresFull = compare.compute(fullIndexPairs, dfA, dfB)\n",
    "\n",
    "    matchesFullAll = featuresFull[featuresFull.sum(axis=1) > 4]\n",
    "    if len(matchesFullAll) > 0:\n",
    "        return(returnResultsDF(matchesFullAll))\n",
    "    else:\n",
    "        matchesFull = featuresFull[featuresFull.sum(axis=1) > 3]\n",
    "        if len(matchesFull) >0:\n",
    "            return(returnResultsDF(matchesFull))\n",
    "    #return the match/matches with highest sum. Maybe try >4 first then >3. for row in frame, \n",
    "    #grab id then return the full dict entry of the id\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Return Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######## RETURN FROM MULTIINDEX\n",
    "\n",
    "def returnResultsMI(pairs):\n",
    "    data = pairs.to_frame(index = False)[0]\n",
    "    i = 0\n",
    "    grab_ids = []\n",
    "    while i < len(data):\n",
    "        grab_ids.append(data[i])\n",
    "        i+=1 \n",
    "    for grab_id in grab_ids:\n",
    "        result = dfD.loc[grab_id].to_string(header = False, index = False)\n",
    "        results.append(result)\n",
    "    return results\n",
    "\n",
    "def returnResultsDF(pairs):\n",
    "    pairs2 = pairs.index\n",
    "    data = pairs2.to_frame(index = False)[0]\n",
    "    i = 0\n",
    "    grab_ids = []\n",
    "    while i < len(data):\n",
    "        grab_ids.append(data[i])\n",
    "        i+=1   \n",
    "    for grab_id in grab_ids:\n",
    "        result = dfD.loc[grab_id].to_string(header = False, index = False)\n",
    "        results.append(result)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Main Method to Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Do this later\n",
    "### MAIN METHOD\n",
    "# First, check for exact match overall FULL\n",
    "# results = []\n",
    "# blockIndexer = recordlinkage.BlockIndex(on=['name', 'addr', 'city', 'ctry', 'code'])\n",
    "# blockIndexPairs = blockIndexer.index(dfA, dfB)\n",
    "# if len(blockIndexPairs) <= 0:\n",
    "#     runBlock()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Now perform Edit distance if multiple results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "INSERTION_PENALTY = 1\n",
    "DELETION_PENALTY = 1\n",
    "# This substitution penalty differentiates from Levenshtein cost (would be 1)\n",
    "SUBSTITUTION_PENALTY = 2\n",
    "ALLOWED_LEVELS = [\"word\", \"char\"]\n",
    "LEVEL = \"word\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_cost(D, i, j, token_X, token_Y):\n",
    "    relative_subst_cost = 0 if token_X == token_Y else SUBSTITUTION_PENALTY\n",
    "    return min(D[i-1, j] + INSERTION_PENALTY, D[i, j-1] + DELETION_PENALTY, D[i-1, j-1] + relative_subst_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize_string(string, level=\"word\"):\n",
    "    assert level in ALLOWED_LEVELS\n",
    "    if level is \"word\":\n",
    "        return string.split(\" \")\n",
    "    else:\n",
    "        return list(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def minimum_edit_distance(string1, string2, level=\"word\"):\n",
    "    \"\"\"The function uses the dynamic programming approach from Wagner-Fischer to compute the minimum edit distance\n",
    "    between two sequences.\n",
    "    :param string1 first sequence\n",
    "    :param string2 second sequence\n",
    "    :param level defines on which granularity the algorithm will be applied. \"word\" specifies the token to\n",
    "    be sequential words while \"char\" applies the algorithm on a character-by-character level\"\"\"\n",
    "    # Call tokenize string on the two address strings that were passed to the method\n",
    "    string1_tokens = tokenize_string(string1, level)\n",
    "    string2_tokens = tokenize_string(string2, level)\n",
    "    n = len(string1_tokens)\n",
    "    m = len(string2_tokens) \n",
    "    D = np.zeros((n, m))\n",
    " \n",
    "    for i in range(n):\n",
    "        for j in range(m):\n",
    "            if j == 0:\n",
    "                D[i,j] = i\n",
    "            elif i == 0:\n",
    "                D[i,j] = j\n",
    "            else:\n",
    "                D[i,j] = compute_cost(D, i, j, string1_tokens[i], string2_tokens[j])\n",
    " \n",
    "    return string2_tokens, D[n-1, m-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preProcess(column):\n",
    "    # convert any unicode data into ASCII characters\n",
    "    column = unidecode(column)\n",
    "    # ignore new lines\n",
    "    column = re.sub('\\n', ' ', column)\n",
    "    # ignore special characters\n",
    "    column = re.sub('-', '', column)\n",
    "    column = re.sub('/', ' ', column)\n",
    "    column = re.sub(\"'\", '', column)\n",
    "    column = re.sub(\",\", '', column)\n",
    "    column = re.sub(\":\", ' ', column)\n",
    "    # ignore extra white space\n",
    "    column = re.sub('  +', ' ', column)\n",
    "    # ignore casing\n",
    "    column = column.strip().strip('\"').strip(\"'\").lower().strip()\n",
    "    if not column :\n",
    "        column = None\n",
    "    return column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect user entry and run against record linkage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:recordlinkage:indexing - performance warning - A full index can result in large number of record pairs.\n"
     ]
    }
   ],
   "source": [
    "name = \"1 mobile LIMITED\"\n",
    "addr = \"30 CITY ROADS\"\n",
    "city = \"LONDON\"\n",
    "ctry=\"UK\"\n",
    "code=\"EC1Y 2AB\"\n",
    "with open ('user_input_file.csv', 'w', newline='') as csvfile:\n",
    "    fieldnames = ['id', 'name', 'addr', 'city', 'ctry', 'code']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerow({'id' : \"1\", 'name': name, 'addr': addr, 'city':city, 'ctry':ctry, 'code':code})\n",
    "csvfile.close()\n",
    "\n",
    "dfA = pd.read_csv(\"companies_final.csv\")\n",
    "dfB = pd.read_csv('user_input_file.csv')\n",
    "dfD = pd.read_csv(\"companies_dict.csv\")\n",
    "dfA.drop('id', axis=1)\n",
    "dfB.drop('id', axis=1)\n",
    "\n",
    "results = []\n",
    "blockIndexer = recordlinkage.BlockIndex(on=['name', 'addr', 'city', 'ctry', 'code'])\n",
    "blockIndexPairs = blockIndexer.index(dfA, dfB)\n",
    "if len(blockIndexPairs) <= 0:\n",
    "    runBlock()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output to User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def output(results):\n",
    "    response_rl = \"No matching address was found!\"\n",
    "    if len(results) == 1:\n",
    "        response_rl = results[0]\n",
    "    user_entry = name + \" \" + addr + \" \" + city + \" \" + ctry + \" \" + code \n",
    "    user_proc = preProcess(user_entry)\n",
    "    min_dist = 9999\n",
    "    if 1 < len(results) < 4:\n",
    "        for result in results:\n",
    "            result_proc = preProcess(result)\n",
    "            dist = minimum_edit_distance(result_proc, user_proc)[1]\n",
    "            if (dist < min_dist):\n",
    "                min_dist = dist\n",
    "                response_rl = result\n",
    "    print(\"User entry:\", user_entry)\n",
    "    print(\"Response:\", response_rl)\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name = \"1 MOBile LIMITED\"\n",
    "addr = \"30 CITY ROADS\"\n",
    "city = \"LONDON\"\n",
    "ctry=\"UK\"\n",
    "code=\"EC1Y 2AB\"\n",
    "with open ('user_input_file.csv', 'w', newline='') as csvfile:\n",
    "    fieldnames = ['id', 'name', 'addr', 'city', 'ctry', 'code']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerow({'id' : \"1\", 'name': name, 'addr': addr, 'city':city, 'ctry':ctry, 'code':code})\n",
    "csvfile.close()\n",
    "\n",
    "dfA = pd.read_csv(\"companies_final.csv\")\n",
    "dfB = pd.read_csv('user_input_file.csv')\n",
    "dfD = pd.read_csv(\"companies_dict.csv\")\n",
    "dfA.drop('id', axis=1)\n",
    "dfB.drop('id', axis=1)\n",
    "\n",
    "results = []\n",
    "blockIndexer = recordlinkage.BlockIndex(on=['name', 'addr', 'city', 'ctry', 'code'])\n",
    "blockIndexPairs = blockIndexer.index(dfA, dfB)\n",
    "if len(blockIndexPairs) <= 0:\n",
    "    runBlock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name = \"1 MOBILE LIMITED\"\n",
    "addr = \"400 Center Pointe Lane\"\n",
    "city = \"LONDON\"\n",
    "ctry=\"UK\"\n",
    "code=\"EC1Y 2AB\"\n",
    "with open ('user_input_file2.csv', 'w', newline='') as csvfile:\n",
    "    fieldnames = ['id', 'name', 'addr', 'city', 'ctry', 'code']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerow({'id' : \"1\", 'name': name, 'addr': addr, 'city':city, 'ctry':ctry, 'code':code})\n",
    "csvfile.close()\n",
    "\n",
    "dfA = pd.read_csv(\"companies_final.csv\")\n",
    "dfB = pd.read_csv('user_input_file2.csv')\n",
    "dfD = pd.read_csv(\"companies_dict.csv\")\n",
    "dfA.drop('id', axis=1)\n",
    "dfB.drop('id', axis=1)\n",
    "\n",
    "results = []\n",
    "blockIndexer = recordlinkage.BlockIndex(on=['name', 'addr', 'city', 'ctry', 'code'])\n",
    "blockIndexPairs = blockIndexer.index(dfA, dfB)\n",
    "if len(blockIndexPairs) <= 0:\n",
    "    runBlock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name = \"\"\n",
    "addr = \"COURTYARD SUITE 100 HATTON GARDEN\"\n",
    "city = \"LONDON\"\n",
    "ctry=\"UK\"\n",
    "code=\"EC1N 8NX\"\n",
    "with open ('user_input_file2.csv', 'w', newline='') as csvfile:\n",
    "    fieldnames = ['id', 'name', 'addr', 'city', 'ctry', 'code']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerow({'id' : \"1\", 'name': name, 'addr': addr, 'city':city, 'ctry':ctry, 'code':code})\n",
    "csvfile.close()\n",
    "\n",
    "dfA = pd.read_csv(\"companies_final.csv\")\n",
    "dfB = pd.read_csv('user_input_file2.csv')\n",
    "dfD = pd.read_csv(\"companies_dict.csv\")\n",
    "dfA.drop('id', axis=1)\n",
    "dfB.drop('id', axis=1)\n",
    "\n",
    "results = []\n",
    "blockIndexer = recordlinkage.BlockIndex(on=['name', 'addr', 'city', 'ctry', 'code'])\n",
    "blockIndexPairs = blockIndexer.index(dfA, dfB)\n",
    "if len(blockIndexPairs) <= 0:\n",
    "    runBlock()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partial Case Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User entry: 1 MOBile LIMITED 30 CITY ROADS LONDON UK EC1Y 2AB\n",
      "Response: 1 MOBILE LIMITED 30 CITY ROAD LONDON EC1Y 2AB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(output(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Incorrect Street Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User entry: 1 MOBILE LIMITED 400 Center Pointe Lane LONDON UK EC1Y 2AB\n",
      "Response: 1 MOBILE LIMITED 30 CITY ROAD LONDON EC1Y 2AB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(output(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aliases and Whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User entry: 1 MOB        LTD 30 CITY ROADS LONDON UK EC1Y 2AB\n",
      "Response: 1 MOBILE LIMITED 30 CITY ROAD LONDON EC1Y 2AB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(output(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exact Unique Addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User entry:  COURTYARD SUITE 100 HATTON GARDEN LONDON UK EC1N 8NX\n",
      "Response: ACTURIS LIMITED COURTYARD SUITE 100 HATTON GAR...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(output(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
